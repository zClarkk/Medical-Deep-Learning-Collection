{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zClarkk/Medical-Deep-Learning-Collection/blob/main/Model_Distillation_and_Ternary_Nets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1rFsbST096l"
      },
      "source": [
        "# Medical Deep Learning\n",
        "## Exercise 5: Model Distillation & Ternary Nets\n",
        "\n",
        "The goal of this exercise is to implement methods that allow to compress deep learning models via model distillation and ternary weights. This enables the use of deep learning in medicine due to its real-time ability and implementation on weaker mobile devices."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mp6xvEmU1i4K",
        "outputId": "942d864a-3a02-4793-daa8-47ddd2a059ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRUWE-KitK2d"
      },
      "outputs": [],
      "source": [
        "#run pip install for pytorch flop counter before first use\n",
        "!pip install onnx wget\n",
        "!pip install --upgrade git+https://github.com/Lyken17/pytorch-OpCounter.git\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import shutil,gzip\n",
        "import wget\n",
        "\n",
        "#some functions to count unique parameters and sparsity are provided\n",
        "def countParameters(net):\n",
        "    model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
        "    params = sum([p.numel() for p in model_parameters])\n",
        "    return params\n",
        "\n",
        "def countUnique(net):\n",
        "    unique = 0\n",
        "    for m in net.modules():\n",
        "        if(isinstance(m,nn.Conv2d)):\n",
        "            unique += len(np.unique(m.weight.data.cpu().flatten().numpy()))\n",
        "    return unique\n",
        "    #print('#unique',unique)\n",
        "\n",
        "def countSparsity(net):\n",
        "    count_nonzero = 0; count_zero = 0\n",
        "    for m in net.modules():\n",
        "        if(isinstance(m, nn.Conv2d)):\n",
        "            count_nonzero += torch.sum((m.weight.data!=0).float())\n",
        "            count_zero += torch.sum((m.weight.data==0).float())\n",
        "    return count_zero/(count_zero+count_nonzero)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oN_q027096p"
      },
      "source": [
        "## Dataset\n",
        "We will use the data of the Patch Camelyon (tupac16) Challenge. It consists of $327\\,680$ color images extracted from histopathologic scans of lymph node sections. The task is to classify the presence of metastatic tissue (global binary labels are given). The images were preprocessed to a spatial dimension of $48\\times48$ and split to 65k for training and 16k for testing images. See [here](https://www.kaggle.com/competitions/histopathologic-cancer-detection/overview) for further details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kHfFFKUtcTY"
      },
      "outputs": [],
      "source": [
        "#loading the patch-based wholeslide histopathology data (uint8) and converting it to torch tensors\n",
        "import os\n",
        "\n",
        "dataset_url = #REDACTED\n",
        "\n",
        "def get_data(data_url):\n",
        "    filename = './patchCamelyon8c.mat'\n",
        "    if not os.path.exists(filename):\n",
        "        filename = wget.download(data_url)\n",
        "\n",
        "get_data(dataset_url)\n",
        "\n",
        "\n",
        "data = scipy.io.loadmat('patchCamelyon8c.mat')\n",
        "\n",
        "img_train = torch.from_numpy(data['img_train'].astype('float32')/255)\n",
        "img_test = torch.from_numpy(data['img_test'].astype('float32')/255)\n",
        "\n",
        "label_train = torch.from_numpy(data['label_train']).long()\n",
        "label_test = torch.from_numpy(data['label_test']).long()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZISt9j2Q096p"
      },
      "source": [
        "Let's visualize an example for the two classes. You can run the cell multiple times, getting each time new random examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEZu_YrN096p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "6d5001a9-bc90-497d-de30-b62bc940cfb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index for no metastatic tissue: 38939\n",
            "index for metastatic tissue: 34097\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, [ax1, ax2] = plt.subplots(1, 2)\n",
        "idx_negative = torch.where(label_train.squeeze() == 0)[0]\n",
        "idx_negative = idx_negative[torch.randperm(len(idx_negative))[0]]\n",
        "\n",
        "idx_positive = torch.where(label_train.squeeze() == 1)[0]\n",
        "idx_positive = idx_positive[torch.randperm(len(idx_positive))[0]]\n",
        "\n",
        "print('index for no metastatic tissue:', idx_negative.item())\n",
        "print('index for metastatic tissue:', idx_positive.item())\n",
        "\n",
        "ax1.imshow(img_train[idx_negative].permute(1, 2, 0))\n",
        "ax1.set_title('no metastatic tissue')\n",
        "ax2.imshow(img_train[idx_positive].permute(1, 2, 0))\n",
        "ax2.set_title('metastatic tissue')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikbrJon6096q"
      },
      "source": [
        "We load a pretrained `VGG11`, inspect its architecture and gather some computational information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKHf1__JtM6x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c48c477-0b5a-419d-a590-a31cb400a6a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "VGG                                      [128, 1000]               --\n",
              "├─Sequential: 1-1                        [128, 512, 1, 1]          --\n",
              "│    └─Conv2d: 2-1                       [128, 64, 48, 48]         1,792\n",
              "│    └─BatchNorm2d: 2-2                  [128, 64, 48, 48]         128\n",
              "│    └─ReLU: 2-3                         [128, 64, 48, 48]         --\n",
              "│    └─MaxPool2d: 2-4                    [128, 64, 24, 24]         --\n",
              "│    └─Conv2d: 2-5                       [128, 128, 24, 24]        73,856\n",
              "│    └─BatchNorm2d: 2-6                  [128, 128, 24, 24]        256\n",
              "│    └─ReLU: 2-7                         [128, 128, 24, 24]        --\n",
              "│    └─MaxPool2d: 2-8                    [128, 128, 12, 12]        --\n",
              "│    └─Conv2d: 2-9                       [128, 256, 12, 12]        295,168\n",
              "│    └─BatchNorm2d: 2-10                 [128, 256, 12, 12]        512\n",
              "│    └─ReLU: 2-11                        [128, 256, 12, 12]        --\n",
              "│    └─Conv2d: 2-12                      [128, 256, 12, 12]        590,080\n",
              "│    └─BatchNorm2d: 2-13                 [128, 256, 12, 12]        512\n",
              "│    └─ReLU: 2-14                        [128, 256, 12, 12]        --\n",
              "│    └─MaxPool2d: 2-15                   [128, 256, 6, 6]          --\n",
              "│    └─Conv2d: 2-16                      [128, 512, 6, 6]          1,180,160\n",
              "│    └─BatchNorm2d: 2-17                 [128, 512, 6, 6]          1,024\n",
              "│    └─ReLU: 2-18                        [128, 512, 6, 6]          --\n",
              "│    └─Conv2d: 2-19                      [128, 512, 6, 6]          2,359,808\n",
              "│    └─BatchNorm2d: 2-20                 [128, 512, 6, 6]          1,024\n",
              "│    └─ReLU: 2-21                        [128, 512, 6, 6]          --\n",
              "│    └─MaxPool2d: 2-22                   [128, 512, 3, 3]          --\n",
              "│    └─Conv2d: 2-23                      [128, 512, 3, 3]          2,359,808\n",
              "│    └─BatchNorm2d: 2-24                 [128, 512, 3, 3]          1,024\n",
              "│    └─ReLU: 2-25                        [128, 512, 3, 3]          --\n",
              "│    └─Conv2d: 2-26                      [128, 512, 3, 3]          2,359,808\n",
              "│    └─BatchNorm2d: 2-27                 [128, 512, 3, 3]          1,024\n",
              "│    └─ReLU: 2-28                        [128, 512, 3, 3]          --\n",
              "│    └─MaxPool2d: 2-29                   [128, 512, 1, 1]          --\n",
              "├─AdaptiveAvgPool2d: 1-2                 [128, 512, 7, 7]          --\n",
              "├─Sequential: 1-3                        [128, 1000]               --\n",
              "│    └─Linear: 2-30                      [128, 4096]               102,764,544\n",
              "│    └─ReLU: 2-31                        [128, 4096]               --\n",
              "│    └─Dropout: 2-32                     [128, 4096]               --\n",
              "│    └─Linear: 2-33                      [128, 4096]               16,781,312\n",
              "│    └─ReLU: 2-34                        [128, 4096]               --\n",
              "│    └─Dropout: 2-35                     [128, 4096]               --\n",
              "│    └─Linear: 2-36                      [128, 1000]               4,097,000\n",
              "==========================================================================================\n",
              "Total params: 132,868,840\n",
              "Trainable params: 132,868,840\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 59.87\n",
              "==========================================================================================\n",
              "Input size (MB): 3.54\n",
              "Forward/backward pass size (MB): 707.76\n",
              "Params size (MB): 531.48\n",
              "Estimated Total Size (MB): 1242.78\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "net = torchvision.models.vgg11_bn(pretrained='True')\n",
        "\n",
        "summary(net, (128, 3, 48, 48))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8t7zLpM096q"
      },
      "source": [
        "## Task 0 (15 points): Modify a pretrained VGG11_BN network for the given training data\n",
        "Complete the function below, which returns a VGG11-Net with its architecture modified accordingly to match the tupac16 dataset.\n",
        "+ Replace the layer `net.avgpool` with an adaptive average pool of output size $1\\times1$\n",
        "+ Create a new classifier as `nn.Sequential` with two linear layers ($512\\times256$ and $256\\times2$) including one ReLU and no batch-norm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4jU8PaZ096r"
      },
      "outputs": [],
      "source": [
        "def tupac16_vgg11():\n",
        "    net = torchvision.models.vgg11_bn(pretrained='True')\n",
        "    net.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "    net.classifier = nn.Sequential(nn.Linear(512,256),nn.ReLU(),nn.Linear(256,2))\n",
        "\n",
        "    return net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGQJ_xoC096r"
      },
      "source": [
        "Check the reduced parameter count using `summary` from `torchinfo`. Your should obtain about $9\\,357\\,826$ parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAIhDhdQ096r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b7e277c-7b93-448d-aae0-d1d520773b28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "VGG                                      [128, 2]                  --\n",
              "├─Sequential: 1-1                        [128, 512, 1, 1]          --\n",
              "│    └─Conv2d: 2-1                       [128, 64, 48, 48]         1,792\n",
              "│    └─BatchNorm2d: 2-2                  [128, 64, 48, 48]         128\n",
              "│    └─ReLU: 2-3                         [128, 64, 48, 48]         --\n",
              "│    └─MaxPool2d: 2-4                    [128, 64, 24, 24]         --\n",
              "│    └─Conv2d: 2-5                       [128, 128, 24, 24]        73,856\n",
              "│    └─BatchNorm2d: 2-6                  [128, 128, 24, 24]        256\n",
              "│    └─ReLU: 2-7                         [128, 128, 24, 24]        --\n",
              "│    └─MaxPool2d: 2-8                    [128, 128, 12, 12]        --\n",
              "│    └─Conv2d: 2-9                       [128, 256, 12, 12]        295,168\n",
              "│    └─BatchNorm2d: 2-10                 [128, 256, 12, 12]        512\n",
              "│    └─ReLU: 2-11                        [128, 256, 12, 12]        --\n",
              "│    └─Conv2d: 2-12                      [128, 256, 12, 12]        590,080\n",
              "│    └─BatchNorm2d: 2-13                 [128, 256, 12, 12]        512\n",
              "│    └─ReLU: 2-14                        [128, 256, 12, 12]        --\n",
              "│    └─MaxPool2d: 2-15                   [128, 256, 6, 6]          --\n",
              "│    └─Conv2d: 2-16                      [128, 512, 6, 6]          1,180,160\n",
              "│    └─BatchNorm2d: 2-17                 [128, 512, 6, 6]          1,024\n",
              "│    └─ReLU: 2-18                        [128, 512, 6, 6]          --\n",
              "│    └─Conv2d: 2-19                      [128, 512, 6, 6]          2,359,808\n",
              "│    └─BatchNorm2d: 2-20                 [128, 512, 6, 6]          1,024\n",
              "│    └─ReLU: 2-21                        [128, 512, 6, 6]          --\n",
              "│    └─MaxPool2d: 2-22                   [128, 512, 3, 3]          --\n",
              "│    └─Conv2d: 2-23                      [128, 512, 3, 3]          2,359,808\n",
              "│    └─BatchNorm2d: 2-24                 [128, 512, 3, 3]          1,024\n",
              "│    └─ReLU: 2-25                        [128, 512, 3, 3]          --\n",
              "│    └─Conv2d: 2-26                      [128, 512, 3, 3]          2,359,808\n",
              "│    └─BatchNorm2d: 2-27                 [128, 512, 3, 3]          1,024\n",
              "│    └─ReLU: 2-28                        [128, 512, 3, 3]          --\n",
              "│    └─MaxPool2d: 2-29                   [128, 512, 1, 1]          --\n",
              "├─AdaptiveAvgPool2d: 1-2                 [128, 512, 1, 1]          --\n",
              "├─Sequential: 1-3                        [128, 2]                  --\n",
              "│    └─Linear: 2-30                      [128, 256]                131,328\n",
              "│    └─ReLU: 2-31                        [128, 256]                --\n",
              "│    └─Linear: 2-32                      [128, 2]                  514\n",
              "==========================================================================================\n",
              "Total params: 9,357,826\n",
              "Trainable params: 9,357,826\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 44.06\n",
              "==========================================================================================\n",
              "Input size (MB): 3.54\n",
              "Forward/backward pass size (MB): 698.62\n",
              "Params size (MB): 37.43\n",
              "Estimated Total Size (MB): 739.59\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "net = tupac16_vgg11()\n",
        "summary(net, (128, 3, 48, 48))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyloBALe096r"
      },
      "source": [
        "## Task1 (25 points): Fine tuning\n",
        "Fine-tune this network for 16 sub-epochs on the tupac16 dataset. One sub-epoch is defined as a random quarter of the training pathes. Use `torch.randperm` to generate the needed indices for every epoch. The batch size should be 128. Choose Adam as an optimizer with an initial learning rate of 0.0005 and an exponential learning rate scheduler with `gamma=0.9`. After training, evaluate the model on the test data. It should yield an accuracy about $94\\%$.\n",
        "\n",
        "**Note:** Task 2 and 3 can be performed independently, but you should store each trained network under a new filename (for comparisons). In the following all techniques should only be applied to the feature-part of the network (and not the classifier layers).\n",
        "\n",
        "**Hint**: If you struggle with implementing of the training routine, have a look at the previous exercises."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(img_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCVM05Je3wKV",
        "outputId": "f2e6d009-ea6c-49e7-f556-a2ecf23dc6f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65536"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_loss(net):\n",
        "  tl = 0\n",
        "  for x in net.modules():\n",
        "    if isinstance(x,nn.BatchNorm2d):\n",
        "      tl +=sum(abs(x.bias))\n",
        "      tl +=sum(abs(x.weight))\n",
        "\n",
        "  return tl"
      ],
      "metadata": {
        "id": "a1evngXL8g63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqKw4fzMVd4Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(net,custom_loss=False):\n",
        "  net.cuda()\n",
        "\n",
        "  num_epochs = 16\n",
        "\n",
        "  # optimizer\n",
        "  optimizer = torch.optim.Adam(net.parameters(), 0.0005)\n",
        "\n",
        "  # learning rate scheduler\n",
        "  lr_scheduler= torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma=0.9)\n",
        "\n",
        "  # criterion\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss().cuda()\n",
        "  if custom_loss:\n",
        "    pass\n",
        "\n",
        "  # statistics\n",
        "  train_loss = torch.zeros(num_epochs, device='cuda')\n",
        "  train_acc = torch.zeros_like(train_loss)\n",
        "\n",
        "\n",
        "  # for num_epochs\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      # train mode\n",
        "      net.train()\n",
        "\n",
        "      rand = torch.randperm(len(img_train))\n",
        "      for i in range(0,len(img_train)//4,128):\n",
        "          input = img_train[rand[i:i+128]].cuda()\n",
        "          target = label_train[0][rand[i:i+128]].cuda()\n",
        "          output = net(input)\n",
        "          loss = criterion(output,target)\n",
        "          if custom_loss:\n",
        "            loss+=0.04*my_loss(net)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          # statistics\n",
        "          train_loss[epoch] += loss.detach()\n",
        "          train_acc[epoch] += torch.mean((torch.argmax(output, dim=-1) == target).float())\n",
        "\n",
        "      # update learning rate\n",
        "      lr_scheduler.step()\n",
        "      # todo\n",
        "\n",
        "      train_loss[epoch] /= len(img_train)//4/128\n",
        "      train_acc[epoch] /=  len(img_train)//4/128\n",
        "\n",
        "      # output\n",
        "      print('Epoch {} (train) -- loss: {:.4f} accuracy: {:.4f}'.format(epoch, train_loss[epoch].item(), train_acc[epoch].item()))\n",
        "  return net\n",
        "# todo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(net):\n",
        "  net.eval()\n",
        "  acc = 0\n",
        "  for i in range(0,len(img_test),32):\n",
        "    input = img_test[i:i+128].cuda()\n",
        "    target = label_test[0][i:i+128].cuda()\n",
        "    output = net(input)\n",
        "    acc += torch.mean((torch.argmax(output, dim=-1) == target).float())\n",
        "  print(f\"Test accuracy: {acc/(len(img_test)//32)}\")"
      ],
      "metadata": {
        "id": "f39R28a05jgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = tupac16_vgg11()\n",
        "net = train(net)\n",
        "evaluate(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck2hVlL86d61",
        "outputId": "81d31aa7-543d-4949-ad84-ddbeb238784d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 (train) -- loss: 0.3454 accuracy: 0.8488\n",
            "Epoch 1 (train) -- loss: 0.2548 accuracy: 0.8977\n",
            "Epoch 2 (train) -- loss: 0.2070 accuracy: 0.9206\n",
            "Epoch 3 (train) -- loss: 0.1826 accuracy: 0.9301\n",
            "Epoch 4 (train) -- loss: 0.1606 accuracy: 0.9387\n",
            "Epoch 5 (train) -- loss: 0.1389 accuracy: 0.9505\n",
            "Epoch 6 (train) -- loss: 0.1099 accuracy: 0.9596\n",
            "Epoch 7 (train) -- loss: 0.1026 accuracy: 0.9626\n",
            "Epoch 8 (train) -- loss: 0.0781 accuracy: 0.9731\n",
            "Epoch 9 (train) -- loss: 0.0762 accuracy: 0.9731\n",
            "Epoch 10 (train) -- loss: 0.0647 accuracy: 0.9781\n",
            "Epoch 11 (train) -- loss: 0.0492 accuracy: 0.9832\n",
            "Epoch 12 (train) -- loss: 0.0422 accuracy: 0.9855\n",
            "Epoch 13 (train) -- loss: 0.0375 accuracy: 0.9881\n",
            "Epoch 14 (train) -- loss: 0.0319 accuracy: 0.9899\n",
            "Epoch 15 (train) -- loss: 0.0258 accuracy: 0.9915\n",
            "Test accuracy: 0.9414825439453125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdlUWCNc096r"
      },
      "source": [
        "## Task 2 (60 points): Network Pruning through increased Sparsity\n",
        "+ Start with the same modified, pre-trained (not fine-tuned) vgg11_bn as before by calling your `tupac16_vgg11` method.\n",
        "+ Reuse the training routine from above.\n",
        "+ Add a sparsity promoting L1-loss (sum of absolute values) with a weight factor of 0.04 to the classification loss on the weights and bias of each BatchNorm2d.\n",
        "    + Therefor iterate over all modules of the net using `modules()` and determine the layer type using `isinstance()`\n",
        "+ Retrain the network.\n",
        "+ Evaluate its test accuracy (will drop slightly to ~89%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLFzc3vmm-qi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a072970-bd2d-4302-a20b-3843118cc8e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 (train) -- loss: 74.5117 accuracy: 0.8522\n",
            "Epoch 1 (train) -- loss: 61.6916 accuracy: 0.8974\n",
            "Epoch 2 (train) -- loss: 50.7317 accuracy: 0.9127\n",
            "Epoch 3 (train) -- loss: 41.5752 accuracy: 0.9166\n",
            "Epoch 4 (train) -- loss: 34.1936 accuracy: 0.9170\n",
            "Epoch 5 (train) -- loss: 28.6857 accuracy: 0.9136\n",
            "Epoch 6 (train) -- loss: 24.8101 accuracy: 0.9158\n",
            "Epoch 7 (train) -- loss: 22.0793 accuracy: 0.9127\n",
            "Epoch 8 (train) -- loss: 20.0344 accuracy: 0.9172\n",
            "Epoch 9 (train) -- loss: 18.4257 accuracy: 0.9203\n",
            "Epoch 10 (train) -- loss: 17.0958 accuracy: 0.9233\n",
            "Epoch 11 (train) -- loss: 15.9833 accuracy: 0.9247\n",
            "Epoch 12 (train) -- loss: 15.0110 accuracy: 0.9285\n",
            "Epoch 13 (train) -- loss: 14.1847 accuracy: 0.9294\n",
            "Epoch 14 (train) -- loss: 13.4591 accuracy: 0.9285\n",
            "Epoch 15 (train) -- loss: 12.8136 accuracy: 0.9360\n",
            "Test accuracy: 0.9016672968864441\n"
          ]
        }
      ],
      "source": [
        "# Task 2\n",
        "net = tupac16_vgg11()\n",
        "net = train(net,True)\n",
        "evaluate(net)\n",
        "# todo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net,'tupac_sparse_net.pth')"
      ],
      "metadata": {
        "id": "Le4e3yCQ_-Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOMqQFQ096r"
      },
      "source": [
        "Write a function that determines a threshold for input/output neurons to be set to zero (the ones which have been reduced in absolute value using the sparsity constraint). You can use the function `topk`, which outputs both the values and indices sorted around a chosen quantile/percentile. Here we simply use the median to set 50% of values to zero.\n",
        "\n",
        "When applied correctly (as incoming & outgoing mask) for each Conv2d layer, it reduces the nonzero parameters by ~75% (the first incoming & last outgoing Conv2d are not masked).\n",
        "Note that BatchNorm has four tensors and two index masks have to be applied as follows:\n",
        "\n",
        "`B = A[idx_next,:,:,:][:,idx_prev,:,:]`\n",
        "\n",
        "Now you can replace all Conv2d and BatchNorm2d layers with smaller filters (and copy their weights) so that we have the following sequence of channels: 3, 32, 64, (2x)128, (3x)256, 512.\n",
        "Evaluate the slimmed network (you could observe a slight improvement to ~92%) and confirm that the required computations are reduced to 12 GFlops."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0DMYXwivPPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd4eaa9-8788-4e34-b105-17269706f5ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#params before 9225984\n",
            "#features sparsity tensor(0., device='cuda:0')\n",
            "before torch.Size([64, 3, 3, 3])\n",
            "after torch.Size([32, 3, 3, 3])\n",
            "before torch.Size([128, 64, 3, 3])\n",
            "after torch.Size([64, 32, 3, 3])\n",
            "before torch.Size([256, 128, 3, 3])\n",
            "after torch.Size([128, 64, 3, 3])\n",
            "before torch.Size([256, 256, 3, 3])\n",
            "after torch.Size([128, 128, 3, 3])\n",
            "before torch.Size([512, 256, 3, 3])\n",
            "after torch.Size([256, 128, 3, 3])\n",
            "before torch.Size([512, 512, 3, 3])\n",
            "after torch.Size([256, 256, 3, 3])\n",
            "before torch.Size([512, 512, 3, 3])\n",
            "after torch.Size([256, 256, 3, 3])\n",
            "before torch.Size([512, 512, 3, 3])\n",
            "after torch.Size([512, 256, 3, 3])\n",
            "#params after 2897952\n",
            "#features sparsity tensor(0., device='cuda:0')\n",
            "Accuracy: 0.9076538\n"
          ]
        }
      ],
      "source": [
        "# task 2 Network slimming (construct lean filters)\n",
        "\n",
        "sparsity_s = 0.04\n",
        "ternary = False\n",
        "\n",
        "model_name = 'tupac_sparse'\n",
        "\n",
        "net = torch.load(model_name+'_net.pth')\n",
        "\n",
        "net.eval()\n",
        "net.cuda()\n",
        "last_layer_size = 3\n",
        "last_mask = torch.ones(3).cuda()\n",
        "idx_prev = torch.arange(3).long().cuda()\n",
        "q75 = 0.5\n",
        "print('#params before',countParameters(net.features))\n",
        "print('#features sparsity',countSparsity(net.features))\n",
        "\n",
        "\n",
        "for c in range(len(net.features)-2):\n",
        "    if isinstance(net.features[c], nn.Conv2d):\n",
        "\n",
        "        if(c==25):\n",
        "            q75=1\n",
        "        new_layer_size = int(q75*len(net.features[c].weight))\n",
        "        print(\"before\",net.features[c].weight.shape)\n",
        "        tk =  torch.topk((net.features[c+1].weight.data),int(q75*len(net.features[c+1].weight.data)))\n",
        "        mask = net.features[c+1].weight.data >= tk[0][-1]\n",
        "\n",
        "        new_layer = nn.Conv2d(last_layer_size,new_layer_size,3,1,1,bias=False).cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "          xd = net.features[c].weight[mask]\n",
        "          new_layer.weight[:,:,:,:] = xd[:,idx_prev,:,:]\n",
        "          #new_layer.bias[:] = net.features[c].bias[mask]\n",
        "\n",
        "\n",
        "        new_batchNorm = nn.BatchNorm2d(new_layer_size).cuda()\n",
        "        with torch.no_grad():\n",
        "\n",
        "          new_batchNorm.weight.data[:] = net.features[c+1].weight.data[mask]\n",
        "          new_batchNorm.bias.data[:] = net.features[c+1].bias.data[mask]\n",
        "          new_batchNorm.running_mean.data[:] = net.features[c+1].running_mean.data[mask]\n",
        "          new_batchNorm.running_var.data[:] = net.features[c+1].running_var.data[mask]\n",
        "\n",
        "        with torch.no_grad():\n",
        "          net.features[c] = new_layer\n",
        "\n",
        "        with torch.no_grad():\n",
        "          net.features[c+1] =  new_batchNorm\n",
        "\n",
        "        last_layer_size = new_layer_size\n",
        "        print(\"after\",net.features[c].weight.shape)\n",
        "        idx_prev = mask\n",
        "        q7 = 0.5\n",
        "\n",
        "# evaluation for task 2\n",
        "\n",
        "print('#params after',countParameters(net.features))\n",
        "print('#features sparsity',countSparsity(net.features))\n",
        "\n",
        "idx_epoch = torch.arange(16384).view(128,-1)\n",
        "val_acc = 0\n",
        "\n",
        "for iter in range(idx_epoch.size(1)):\n",
        "    idx_iter = idx_epoch[:,iter]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        #forward path and loss\n",
        "        outputs = net(img_test[idx_iter,:,:,:].cuda())\n",
        "    val_acc += torch.sum((outputs.argmax(1).cpu()==label_test[0,idx_iter]).float())/16384.0\n",
        "\n",
        "print(f\"Accuracy: {val_acc.item():.7f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7JNALR1nWZI",
        "outputId": "0a10de85-03a8-4a81-f3ab-3f186c440882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "VGG                                      --\n",
              "├─Sequential: 1-1                        --\n",
              "│    └─Conv2d: 2-1                       864\n",
              "│    └─BatchNorm2d: 2-2                  64\n",
              "│    └─ReLU: 2-3                         --\n",
              "│    └─MaxPool2d: 2-4                    --\n",
              "│    └─Conv2d: 2-5                       18,432\n",
              "│    └─BatchNorm2d: 2-6                  128\n",
              "│    └─ReLU: 2-7                         --\n",
              "│    └─MaxPool2d: 2-8                    --\n",
              "│    └─Conv2d: 2-9                       73,728\n",
              "│    └─BatchNorm2d: 2-10                 256\n",
              "│    └─ReLU: 2-11                        --\n",
              "│    └─Conv2d: 2-12                      147,456\n",
              "│    └─BatchNorm2d: 2-13                 256\n",
              "│    └─ReLU: 2-14                        --\n",
              "│    └─MaxPool2d: 2-15                   --\n",
              "│    └─Conv2d: 2-16                      294,912\n",
              "│    └─BatchNorm2d: 2-17                 512\n",
              "│    └─ReLU: 2-18                        --\n",
              "│    └─Conv2d: 2-19                      589,824\n",
              "│    └─BatchNorm2d: 2-20                 512\n",
              "│    └─ReLU: 2-21                        --\n",
              "│    └─MaxPool2d: 2-22                   --\n",
              "│    └─Conv2d: 2-23                      589,824\n",
              "│    └─BatchNorm2d: 2-24                 512\n",
              "│    └─ReLU: 2-25                        --\n",
              "│    └─Conv2d: 2-26                      1,179,648\n",
              "│    └─BatchNorm2d: 2-27                 1,024\n",
              "│    └─ReLU: 2-28                        --\n",
              "│    └─MaxPool2d: 2-29                   --\n",
              "├─AdaptiveAvgPool2d: 1-2                 --\n",
              "├─Sequential: 1-3                        --\n",
              "│    └─Linear: 2-30                      131,328\n",
              "│    └─ReLU: 2-31                        --\n",
              "│    └─Linear: 2-32                      514\n",
              "=================================================================\n",
              "Total params: 3,029,794\n",
              "Trainable params: 3,029,794\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqKSg9le096s"
      },
      "source": [
        "## Bonus Task - Ternary Nets:\n",
        "Start with the same modified, pre-trained (not fine-tuned) vgg11_bn as before. Finally, we want to explore, how the memory storage can be reduced with little loss. Here a ternary weight approximation will be used for which we first estimate a per-channel $\\Delta$ for each weight in Conv2d given the rule-of-thumb below.\n",
        "\n",
        "$\\begin{align}\n",
        "    \\Delta &= \\frac{0.7}{n}\\sum^n_{i=1}|W_i|\\\\\n",
        "    \\tilde{W}_i&=\n",
        "    \\begin{cases}\n",
        "        +1, &\\text{ if } W_i > \\Delta\\\\\n",
        "        0,  &\\text{ if } |W_i| \\leq \\Delta\\\\\n",
        "        -1,  &\\text{ else }\n",
        "    \\end{cases}\\\\\n",
        "    n_\\Delta &= \\sum_i|\\tilde{W}_i|\\\\\n",
        "    \\alpha &= \\frac{1}{n_\\Delta}\\sum_i|\\tilde{W}_i||W_i|\n",
        "\\end{align}$\n",
        "\n",
        "Tip: after calculating the absolute values the mean has to be computed over all but the 0-th dimension.\n",
        "The obtained ternary weights have lost their magnitude, therefore the parameter $\\alpha$ (again per-channel) is computed and multiplied with the weight tensor.\n",
        "\n",
        "Test your function with the check implemented below. For a $128\\times64\\times3\\times3$ kernel the number of unique entries is reduced from more than 70 thousand to just 257 ($2 \\cdot 128 + 1$)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = tupac16_vgg11()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRuWJGUXyzV6",
        "outputId": "f0f7a29d-ddd3-4f2c-de0e-a2ec85946c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4ay90rCv3gi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e01cccb-6067-4c64-fa43-cf990e59d5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#unique 73673\n",
            "#unique 257\n"
          ]
        }
      ],
      "source": [
        "# template for function in bonus task\n",
        "def approx_weights(w_in,flag=True):\n",
        "    if(flag):\n",
        "        with torch.no_grad():\n",
        "\n",
        "          a, b, c, d = w_in.size()\n",
        "          delta = 0.7 * torch.mean(w_in, dim=(1, 2, 3))\n",
        "          w_wave = torch.ones_like(w_in) * -1\n",
        "          w_wave[w_in > delta[:, None, None, None]] = 1\n",
        "          w_wave[torch.abs(w_in) <= delta[:, None, None, None]] = 0\n",
        "          n_delta = torch.sum(torch.abs(w_wave), dim=(1, 2, 3))\n",
        "          alpha = torch.sum(torch.abs(w_wave) * torch.abs(w_in), dim=(1, 2, 3)) / n_delta\n",
        "          w_out = w_wave * alpha[:, None, None, None]\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "        w_out = w_in\n",
        "    return w_out\n",
        "\n",
        "# check the number of unique values before/after ternary approximation\n",
        "w_in = net.features[4].weight.clone().detach()\n",
        "w_approx = approx_weights(w_in,True)\n",
        "print('#unique',len(np.unique(w_in.data.cpu().flatten().numpy())))\n",
        "print('#unique',len(np.unique(w_approx.data.cpu().flatten().numpy())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9eS27hi096s"
      },
      "source": [
        "To effectively train a network with weight quantisation, it is important to only use the ternary weights during forward/backward path, but update their gradients in full precision.\n",
        "\n",
        "Implement a loop that stores full precision weights in a list of tensors and replaces the `.data` values with their approximation just before calling the forward pass (and zero_grad).\n",
        "Reassign these backup copies after `loss.backward()` and `before optimizer.step()`. Retrain your network and take care to perform the weight quantisation the same way during test evaluation. The test accuracy should be around 85-90% during the epochs.\n",
        "\n",
        "**Tip:** you could use `.pop(0)` to (iteratively) access and remove the first object of a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0jIeCbZ096s"
      },
      "outputs": [],
      "source": [
        "# todo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_and_store(net):\n",
        "  copies = []\n",
        "  for c in range(len(net.features)-2):\n",
        "      if isinstance(net.features[c], nn.Conv2d):\n",
        "          w_in = net.features[c].weight.data\n",
        "          w_out = approx_weights(w_in,flag=True)\n",
        "          copies.append(w_in)\n",
        "          with torch.no_grad():\n",
        "              net.features[c].weight.data[:] = w_out\n",
        "  return net, copies"
      ],
      "metadata": {
        "id": "yGnIRf8x5ksN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recover(net,copies):\n",
        "    for c in range(len(net.features)-1,-1,-1):\n",
        "        if isinstance(net.features[c], nn.Conv2d):\n",
        "          w_old = copies.pop()\n",
        "          with torch.no_grad():\n",
        "            net.features[c].weight.data[:] = w_old\n",
        "    return net"
      ],
      "metadata": {
        "id": "YGHZhjwD6cEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ternary(net):\n",
        "  net.cuda()\n",
        "\n",
        "  num_epochs = 16\n",
        "\n",
        "  # optimizer\n",
        "  optimizer = torch.optim.Adam(net.parameters(), 0.0005)\n",
        "\n",
        "  # learning rate scheduler\n",
        "  lr_scheduler= torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma=0.9)\n",
        "\n",
        "  # criterion\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "\n",
        "  # statistics\n",
        "  train_loss = torch.zeros(num_epochs, device='cuda')\n",
        "  train_acc = torch.zeros_like(train_loss)\n",
        "\n",
        "\n",
        "  # for num_epochs\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      # train mode\n",
        "      net.train()\n",
        "\n",
        "      rand = torch.randperm(len(img_train))\n",
        "      for i in range(0,len(img_train)//4,128):\n",
        "          input = img_train[rand[i:i+128]].cuda()\n",
        "          target = label_train[0][rand[i:i+128]].cuda()\n",
        "          net, cops = replace_and_store(net)\n",
        "          output = net(input)\n",
        "          loss = criterion(output,target)\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          net = recover(net,cops)\n",
        "          optimizer.step()\n",
        "          # statistics\n",
        "          train_loss[epoch] += loss.detach()\n",
        "          train_acc[epoch] += torch.mean((torch.argmax(output, dim=-1) == target).float())\n",
        "\n",
        "      # update learning rate\n",
        "      lr_scheduler.step()\n",
        "\n",
        "      train_loss[epoch] /= len(img_train)//4/128\n",
        "      train_acc[epoch] /=  len(img_train)//4/128\n",
        "\n",
        "      # output\n",
        "      print('Epoch {} (train) -- loss: {:.4f} accuracy: {:.4f}'.format(epoch, train_loss[epoch].item(), train_acc[epoch].item()))\n",
        "  return net"
      ],
      "metadata": {
        "id": "KDuRnYlV7A7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_ternary(net):\n",
        "  net.eval()\n",
        "  acc = 0\n",
        "  net, cops = replace_and_store(net)\n",
        "  for i in range(0,len(img_test),32):\n",
        "    input = img_test[i:i+128].cuda()\n",
        "    target = label_test[0][i:i+128].cuda()\n",
        "    output = net(input)\n",
        "    acc += torch.mean((torch.argmax(output, dim=-1) == target).float())\n",
        "  print(f\"Test accuracy: {acc/(len(img_test)//32)}\")"
      ],
      "metadata": {
        "id": "QzxD55397mQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = tupac16_vgg11()\n",
        "net = train_ternary(net)\n",
        "evaluate_ternary(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpb6MHHq7szi",
        "outputId": "4e4c8a1f-49b4-493e-bf5e-b1eb1cf01ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG11_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG11_BN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 (train) -- loss: 0.5592 accuracy: 0.7042\n",
            "Epoch 1 (train) -- loss: 0.4307 accuracy: 0.8063\n",
            "Epoch 2 (train) -- loss: 0.4110 accuracy: 0.8151\n",
            "Epoch 3 (train) -- loss: 0.3917 accuracy: 0.8221\n",
            "Epoch 4 (train) -- loss: 0.3892 accuracy: 0.8225\n",
            "Epoch 5 (train) -- loss: 0.3877 accuracy: 0.8248\n",
            "Epoch 6 (train) -- loss: 0.3826 accuracy: 0.8269\n",
            "Epoch 7 (train) -- loss: 0.3735 accuracy: 0.8318\n",
            "Epoch 8 (train) -- loss: 0.3751 accuracy: 0.8327\n",
            "Epoch 9 (train) -- loss: 0.3692 accuracy: 0.8360\n",
            "Epoch 10 (train) -- loss: 0.3630 accuracy: 0.8378\n",
            "Epoch 11 (train) -- loss: 0.3654 accuracy: 0.8353\n",
            "Epoch 12 (train) -- loss: 0.3624 accuracy: 0.8373\n",
            "Epoch 13 (train) -- loss: 0.3602 accuracy: 0.8395\n",
            "Epoch 14 (train) -- loss: 0.3515 accuracy: 0.8438\n",
            "Epoch 15 (train) -- loss: 0.3553 accuracy: 0.8413\n",
            "Test accuracy: 0.830230712890625\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
